{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: 0.975\n",
      "[0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x109ff0400>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "# scipy.special needed for sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are not printed in separate window\n",
    "%matplotlib inline\n",
    "\n",
    "# defines neural network class\n",
    "class neuralNetwork:\n",
    "    \n",
    "    # initialise neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set numer of nodes in each input, hidden, and output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, w_ih and w_ho\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc\n",
    "        \n",
    "        self.wih = (numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes)))\n",
    "        self.who = (numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes)))\n",
    "        \n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2) .T\n",
    "        targets = numpy.array(targets_list, ndmin=2) .T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # error is (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    #query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        \n",
    "        #convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2) .T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "\n",
    "    # backquery the neural network\n",
    "    # using the same termnimology to each item, \n",
    "    # target is values at the right of network\n",
    "    # hidden_output is signal to the right of middle ones\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs\n",
    "\n",
    "# number of input, hidden, and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate is 0.1\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network object\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "# load the mnist training CSV into a list\n",
    "training_data_file = open(\"mnist_dataset/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "# train the neural network\n",
    "\n",
    "# epochs = number of times training set is used for training\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in training set\n",
    "    for record in training_data_list:\n",
    "        # split record by commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create target output values (all 0.01 except target which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "# load mnist test CSV into a list\n",
    "test_data_file = open(\"mnist_dataset/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "# test the neural network\n",
    "\n",
    "# scorecard for how well network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all records in test set\n",
    "for record in test_data_list:\n",
    "    # split by commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "#     print(correct_label, \"correct label\")\n",
    "    # scale and shift inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # index of highest value corresponds to label\n",
    "    label = numpy.argmax(outputs)\n",
    "#     print(label, \"network's answer\")\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else :\n",
    "        # network's answer doesn't match correct ansewr, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "# calculate performance score as fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print(\"Performance:\", scorecard_array.sum() / scorecard_array.size)\n",
    "\n",
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 8\n",
    "# create the output signals for this label\n",
    "targets = numpy.zeros(output_nodes) + 0.01\n",
    "# all_values[0] is the target label for this record\n",
    "targets[label] = 0.99\n",
    "print(targets)\n",
    "\n",
    "# get image data\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "matplotlib.pyplot.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
